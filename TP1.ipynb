{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-learning TP1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce TP1 est d'acquérir les bases nécessaires à la compréhension des réseaux de neurones à partir d'un modèle simple de type Softmax. La tâche d'apprentissage consiste à classifier les images (28 par 28 pixels) de la base MNIST (http://yann.lecun.com/exdb/mnist/) en 10 catégories représentant les chiffres 0-9.\n",
    "\n",
    "Le TP2 consistera à généraliser les concepts de ce TP1 à un réseau de neurones multi-couches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement de la base d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n",
    "    print('download mnist data')\n",
    "    !wget http://deeplearning.net/data/mnist/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la base en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset_loader\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist()\n",
    "#train_set[1][750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez visualiser les différents caractères en changeant l'identifiant de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLnjHKRAueMcpEC54xykQLnjHKRD/HxRXtE9/zbEgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7b1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 903\n",
    "plt.imshow(train_set[0][img_id].reshape(28,28),cmap='Greys')\n",
    "print(\"label: \" + str(train_set[1][img_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Donner les caractéristiques de la base d'apprentissage train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDimDataset(train_set):\n",
    "    n_training = 0\n",
    "    n_feature = 0\n",
    "    n_label = 0\n",
    "    x=train_set[0]\n",
    "    #print x\n",
    "    y=train_set[1]\n",
    "    print y\n",
    "    n_training = len(x)#x.shape[0]\n",
    "    n_feature = x.shape[1]\n",
    "    n_label = len(set(y))\n",
    "    return n_training, n_feature, n_label\n",
    "\n",
    "#getDimDataset (train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,3],[4,5,9,6]]\n",
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ..., 9 8 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_training, n_feature, n_label = getDimDataset(train_set)\n",
    "n_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init(n_feature,n_label):\n",
    "    sigma = 1.\n",
    "    W = np.random.normal(loc=0.0, scale=sigma/np.sqrt(n_feature), size=(n_label,n_feature))\n",
    "    b = np.zeros((W.shape[0],1))\n",
    "    return W,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_feature = 0\n",
    "W,b = init(n_feature,n_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Donner les dimensions de W et b ainsi que le nombre total de paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W dimensions: (10L, 784L)\n",
      "b dimensions: (10L, 1L)\n",
      "Number of parameters: 7850\n"
     ]
    }
   ],
   "source": [
    "def printInfo(W,b):\n",
    "    print(\"W dimensions: \" + str(W.shape))\n",
    "    print(\"b dimensions: \" + str(b.shape))\n",
    "    print(\"Number of parameters: \" + str(b.shape[0]+W.shape[0]*W.shape[1]))\n",
    "    \n",
    "printInfo(W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Implémenter la fonction forward $$z_j = \\sum_{i \\rightarrow j} W_{ij} x_i + b_j$$ où $x_i$ est un pixel de l'image, $W_{ij}$ est la valeur associée à l'arête reliant les unités $i$ et $j$ et $b_j$ est le bias associé à l'unité $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(W,b,X):\n",
    "    \n",
    "    \"\"\"\n",
    "        Perform the forward propagation\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :type W: ndarray\n",
    "        :type B: ndarray\n",
    "        :type X: ndarray\n",
    "        :return: the transformed values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    #for j in X.shape:\n",
    "        #for i in n_feature:\n",
    "    return (np.dot(W,X.T)+b) #np.zeros((W.shape[0],X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10L, 50000L)\n"
     ]
    }
   ],
   "source": [
    "X=train_set[0]\n",
    "f=forward(W,b,X)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Implémenter la fonction softmax $$ \\sigma_i = P(t=i|x,W,b) = \\frac{\\exp{z_i}}{\\sum_k \\exp{z_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "        Perform the softmax transformation to the pre-activation values\n",
    "        :param z: the pre-activation values\n",
    "        :type z: ndarray\n",
    "        :return: the activation values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.max(z, 0)\n",
    "    \n",
    "    return np.exp(z-p)/np.sum(np.exp(z-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionnel: Vérifier que votre implémentation de softmax soit numériquement stable (cf. http://ufldl.stanford.edu/wiki/index.php/Exercise:Softmax_Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Example for testing the numerical stability of softmax\n",
    "# It should return [1., 0. ,0.], not [nan, 0., 0.]\n",
    "z = [1000000,1,100]\n",
    "print(softmax(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Implémenter le calcul du gradient de l'erreur par rapport à $z_i$:\n",
    "$$\\delta z_i = \\sigma_i - 1_{i=l}$$\n",
    "où $l$ est l'étiquette associée à la donnée courante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_out(out, one_hot_batch):\n",
    "    \"\"\"\n",
    "    compute the gradient w.r.t. the pre-activation values of the softmax z_i\n",
    "    :param out: the softmax values\n",
    "    :type out: ndarray\n",
    "    :param one_hot_batch: the one-hot representation of the labels\n",
    "    :type one_hot_batch: ndarray\n",
    "    :return: the gradient w.r.t. z\n",
    "    :rtype: ndarray\n",
    "    \"\"\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Implémenter la fonction du calcul de gradient par rapport aux paramètres: $$\\delta W_{ij} = \\delta z_j x_i$$  $$\\delta b_{j} = \\delta z_j$$ où $\\delta W_{ij}$ est la composante du gradient associée à l'arête reliant les unités $i$ et $j$, $\\delta b_{j}$ est la composante du gradient associée au bias de l'unité $j$, $\\delta z_j$ est le gradient de l'erreur par rapport à l'unité $j$ et $x_i$ est la valeur d'activation de l'unité $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(derror, X):\n",
    "    \"\"\"\n",
    "        Compute the gradient w.r.t. the parameters\n",
    "        :param derror: the gradient w.r.t. z\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :param minibatch_size: the minibatch size\n",
    "        :type derror: ndarray\n",
    "        :type minibatch: ndarray\n",
    "        :type minibatch_size: unsigned\n",
    "        :return: the gradient w.r.t. the parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    grad_w = np.zeros((derror.shape[0],X.shape[1]))\n",
    "    grad_b = np.zeros((derror.shape[0]))\n",
    "    return grad_w,grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Implémenter la fonction de mise à jour des paramètres $$p = p - \\eta \\delta p$$ où $p$ est un paramètre du modèle et $\\delta p$ la composante du gradient associée à p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad_w, grad_b):\n",
    "    \"\"\"\n",
    "        Update the parameters with an update rule\n",
    "        :param eta: the step-size\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param grad_w: the gradient w.r.t. the weights\n",
    "        :param grad_b: the gradient w.r.t. the bias\n",
    "        :type eta: float\n",
    "        :type W: ndarray\n",
    "        :type b: ndarray\n",
    "        :type grad_w: ndarray\n",
    "        :type grad_b: ndarray\n",
    "        :return: the updated parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math,time\n",
    "from IPython.display import clear_output\n",
    "from aux import *\n",
    "\n",
    "# Data structures for plotting\n",
    "g_i = []\n",
    "g_train_loss=[]\n",
    "g_train_acc=[]\n",
    "g_valid_loss=[]\n",
    "g_valid_acc=[]\n",
    "\n",
    "n_training, n_feature, n_label = getDimDataset(train_set)\n",
    "\n",
    "# SGD parameters\n",
    "eta = 0.001\n",
    "batch_size = 500\n",
    "n_batch = int(math.ceil(float(n_training)/batch_size))\n",
    "n_epoch = 100\n",
    "\n",
    "cumul_time = 0.\n",
    "\n",
    "# Initialize the model parameters\n",
    "W,b = init(n_feature,n_label)\n",
    "printInfo(W,b)\n",
    "\n",
    "# Convert the labels to one-hot vector\n",
    "one_hot = np.zeros((n_label,n_training))\n",
    "one_hot[train_set[1],np.arange(n_training)]=1.\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    for j in range(n_batch):\n",
    "\n",
    "        ### Mini-batch creation\n",
    "        minibatch, one_hot_batch, minibatch_size = getMiniBatch(j, batch_size, train_set, one_hot)\n",
    "\n",
    "        prev_time = time.clock()\n",
    "\n",
    "        ### Forward propagation\n",
    "        Z = forward(W,b,minibatch)\n",
    "\n",
    "        ### Compute the softmax\n",
    "        out = softmax(Z)\n",
    "\n",
    "        ### Compute the gradient at the top layer\n",
    "        derror = gradient_out(out,one_hot_batch)\n",
    "\n",
    "        ### Compute the gradient w.r.t. parameters\n",
    "        grad_w,grad_b = gradient(derror, minibatch)\n",
    "\n",
    "        ### Update the parameters\n",
    "        W,b = update(eta, W, b, grad_w, grad_b)\n",
    "        \n",
    "        curr_time = time.clock()\n",
    "        cumul_time += curr_time - prev_time\n",
    "    \n",
    "    ### Training accuracy\n",
    "    train_loss, train_acc = computeLoss(W, b, train_set[0], train_set[1],softmax) \n",
    "    \n",
    "    ### Valid accuracy\n",
    "    valid_loss, valid_acc = computeLoss(W, b, valid_set[0], valid_set[1],softmax) \n",
    "\n",
    "    g_i = np.append(g_i, i)\n",
    "    g_train_loss = np.append(g_train_loss, train_loss)\n",
    "    g_train_acc = np.append(g_train_acc, train_acc)\n",
    "    g_valid_loss = np.append(g_valid_loss, valid_loss)\n",
    "    g_valid_acc = np.append(g_valid_acc, valid_acc)\n",
    "    \n",
    "    result_line = str(i) + \" \" + str(cumul_time) + \" \" + str(train_loss) + \" \" + str(train_acc) + \" \" + str(valid_loss) + \" \" + str(valid_acc) + \" \" + str(eta)\n",
    "    print(result_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(g_i,g_train_loss,label='train_loss')\n",
    "plt.plot(g_i,g_valid_loss,label='valid_loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Negative log-likelihood\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(g_i,1.0-g_train_acc,label='train_acc')\n",
    "plt.plot(g_i,1.0-g_valid_acc,label='valid_acc')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Classification error\")\n",
    "plt.ylim([0.,1.])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Montrer, à l'aide d'une figure, l'effet du step-size (prendre $\\eta$=[0.01,0.1,1.0,10.]) sur les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
